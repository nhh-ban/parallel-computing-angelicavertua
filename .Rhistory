# Method 2
library(tweedie)
library(ggplot2)
library(doParallel)
library(foreach)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
# Create a cluster with available cores
cl <- makeCluster(detectCores())
registerDoParallel(cl)
cl <- makeCluster(detectCores())  # Create a cluster with available cores
clusterExport(cl, varlist = c("df", "MTweedieTests"))  # Export necessary variables and functions
df$share_reject <- parLapply(cl, 1:nrow(df), function(i) {
MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
})
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
cl <- makeCluster(detectCores())  # Create a cluster with available cores
clusterExport(cl, varlist = c("df", "MTweedieTests"))  # Export necessary variables and functions
df$share_reject <- parLapply(cl, 1:nrow(df), function(i) {
MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
})
library(future)
library(furrr)
# Plan for parallel execution
plan(multisession)
# Create a function for parallel execution
parallel_function <- function(i) {
MTests(df$N[i], df$M[i], df$type[i], 0.05)
}
# Use furrr to parallelize the loop and update df$share_reject
df$share_reject <- future_map_dbl(1:nrow(df), ~parallel_function(.x))
# Plan for parallel execution
plan(multisession)
# Create a function for parallel execution
parallel_function <- function(i) {
MTweedieTests(df$N[i], df$M[i], 0.05)
}
# Use furrr to parallelize the loop and update df$share_reject
df$share_reject <- future_map_dbl(1:nrow(df), ~parallel_function(.x))
# Method 3
library(tweedie)
library(ggplot2)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
registerDoParallel(cl)
result <- foreach(j=1:M, .combine='c') %dopar% {
simTweedieTest(N)
} %>% unlist()
stopCluster(cl)
sum(result < sig) / M
}
# Use the modified MTweedieTests function in the original code
df$share_reject <- mapply(MTweedieTests, df$N, df$M, .05)
library(magrittr)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
registerDoParallel(cl)
result <- foreach(j=1:M, .combine='c') %dopar% {
simTweedieTest(N)
} %>% unlist()
stopCluster(cl)
sum(result < sig) / M
}
# Use the modified MTweedieTests function in the original code
df$share_reject <- mapply(MTweedieTests, df$N, df$M, .05)
# timer.r
library(tictoc)
# Source the three methods
source("scripts/method1.r")
setwd("C:/Users/Angelica/OneDrive/Desktop/parallel-computing-angelicavertua")
# timer.r
getwd()
# Source the three methods
source("scripts/method1.r")
source("scripts/method2.r")
library(tweedie)
library(ggplot2)
library(parallel)
library(doParallel)
library(foreach)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
# Parallelize the final loop
future::plan(furrr::multiprocess, workers = 2)
library(future.apply)
# Parallelize the final loop using future.apply
plan(multiprocess)  # Use the "multiprocess" backend
# Set up parallel processing
cl <- makeCluster(detectCores())
clusterExport(cl, c("MTweedieTests", "df"))
# Parallelize the final loop using mclapply
df$share_reject <- mclapply(1:nrow(df), function(i) {
MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
}, mc.cores = length(cl))
# Set up parallel processing using doParallel
cl <- makeCluster(detectCores())
registerDoParallel(cl)
# Parallelize the final loop using foreach
df$share_reject <- foreach(i = 1:nrow(df), .packages = c("tweedie")) %dopar% {
MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
}
# Stop the parallel workers
stopCluster(cl)
library(tweedie)
library(ggplot2)
library(future.apply)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Define MTweedieTests function with parallel execution
MTweedieTests <- function(N, M, sig) {
# Split M simulations into chunks for parallel processing
chunk_size <- M / future::availableCores()
chunks <- split(1:M, rep(1:future::availableCores(), each = chunk_size))
results <- future.apply::future_lapply(chunks, function(chunk) {
sum(replicate(length(chunk), simTweedieTest(N)) < sig) / length(chunk)
})
# Combine results from parallel execution
mean(unlist(results))
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
# Parallelize the computation using MTweedieTests function
plan(multiprocess)  # Use the "multiprocess" backend
## Method 3
library(tweedie)
library(ggplot2)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Define MTweedieTests function with parallel execution
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
clusterExport(cl, c("simTweedieTest"))
clusterEvalQ(cl, library(tweedie))
clusterEvalQ(cl, library(stats))
results <- parLapply(cl, 1:M, function(i) {
simTweedieTest(N)
})
stopCluster(cl)
sum(unlist(results) < sig) / M
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
# Parallelize the computation using MTweedieTests function
df$share_reject <- mapply(MTweedieTests, df$N, df$M, df$share_reject, SIMPLIFY = FALSE, MoreArgs = list(sig = 0.05))
## Method 3
library(tweedie)
library(ggplot2)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Define MTweedieTests function with parallel execution
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
clusterExport(cl, c("simTweedieTest"))
clusterEvalQ(cl, library(tweedie))
clusterEvalQ(cl, library(stats))
results <- parLapply(cl, 1:M, function(i) {
simTweedieTest(N)
})
stopCluster(cl)
sum(unlist(results) < sig) / M
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
# Parallelize the computation using MTweedieTests function
df$share_reject <- mapply(MTweedieTests, df$N, df$M, df$share_reject, SIMPLIFY = FALSE, MoreArgs = list(sig = 0.05))
## Method 3
library(tweedie)
library(ggplot2)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Define MTweedieTests function with parallel execution
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
clusterExport(cl, c("simTweedieTest"))
clusterEvalQ(cl, library(tweedie))
clusterEvalQ(cl, library(stats))
results <- parLapply(cl, 1:M, function(i) {
simTweedieTest(N)
})
stopCluster(cl)
return(sum(unlist(results) < sig) / M)
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
# Parallelize the computation using MTweedieTests function
df$share_reject <- mapply(df$N, df$M, df$share_reject, FUN = MTweedieTests, MoreArgs = list(sig = 0.05))
# Define MTweedieTests function with parallel execution
MTweedieTests <- function(N, M, sig) {
cl <- makeCluster(detectCores())
clusterExport(cl, c("simTweedieTest"))
clusterEvalQ(cl, library(tweedie))
clusterEvalQ(cl, library(stats))
results <- parLapply(cl, 1:M, function(i) {
simTweedieTest(N)
})
stopCluster(cl)
return(sum(unlist(results) < sig) / M)
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
# Parallelize the computation using MTweedieTests function
for (i in 1:nrow(df)) {
df$share_reject[i] <- MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
}
## Method 3
library(tweedie)
library(ggplot2)
library(doParallel)
